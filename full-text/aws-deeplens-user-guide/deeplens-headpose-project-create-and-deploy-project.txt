Create and Deploy the Head Pose Detection Project
Before creating the AWS DeepLens project, your must import the model into AWS DeepLens. Because the original Amazon SageMaker-trained model artifact is converted to a protobuff file, you must treat the transformed model artifact as externally trained.
To import the customized Amazon SageMaker-trained model for head pose detection


Go to the AWS DeepLens console.


Choose Models from the main navigation pane.


Choose Import model.


On the Import model to AWS DeepLens page, do the following:


Under Import source, choose Externally trained model.


Under Model settings, do the following:


For Model artifact path, type the model's S3 URL, e.g., s3://deeplens-sagemaker-models-<my-name>/headpose/TFartifacts/<sagemaker-job-name>/output/frozen_model.pb.


For Model name, type a name for your model, e.g., my-headpose-detection-model.


For Model framework, choose TensorFlow.


For Description - Optional, type a description about the model, if choose to do so.




After importing the model, you can now create an AWS DeepLens project to add the imported model and the published inference Lambda function.
To create a custom AWS DeepLens project for head pose detection


In the AWS DeepLens console, choose Projects from the main navigation pane. 


In the Projects page, choose Create new project.


On the Choose project type page, choose Create a new blank project. Then, choose Next.


On the Specify project details page, do the following:


Under Project information, type a name for your project in the Project name input field and, optionally, give a project description in the Description - Optional input field.


Under Project content, do the following:


Choose Add model. Then, select the radio button next to your head pose detection model imported earlier and choose Add model.


Choose Add function. Then, select the radio button next to the published Lambda function for head pose detection and choose Add function.
The function must be published in AWS Lambda and named with the deeplens- prefix to make it visible here. If you've published multiple versions of the function, make sure to choose the function of the correction version.


Choose Create.


With the project created, you're ready to deploy it to your registered AWS DeepLens device. Make sure to remove any active project from the device before proceeding further.


In the Projects page of the DAWS DeepLensL console, choose the newly created project for head pose detection.


In the selected project details page, choose Deploy to device.


On the Target device page, select the radio button next to your registered device and then choose Review.


On the Review and deploy page, choose Deploy after verifying the project details. 


On the device details page, examine the deployment status by inspecting Device status and Registration status. If they're Online and Registered, respectively, the deployment succeeded. Otherwise, verify that the imported model and the published Lambda function are valid. 


After the project is successfully deployed, you can view the project output in one of the following ways: 


View the JSON-formatted output published by the inference Lambda function in the AWS IoT Core console. For instructions, see View Your AWS DeepLens Project Output in the AWS IoT Console.


View streaming video in a supported web browser. For instructions, View Video Streams from AWS DeepLens Device in Browser.


This completes this tutorial to build and deploy your head pose detection project. 