Copy CSV Data Using the AWS Data Pipeline Console
You can create and use pipelines to copy data from one Amazon S3 bucket to another.
Topics
 Create the Pipeline
 Save and Validate Your Pipeline
 Activate Your Pipeline
 Monitor the Pipeline Runs
 (Optional) Delete Your Pipeline
Create the Pipeline
First, create the pipeline.
To create the pipeline


Open the AWS Data Pipeline console at https://console.aws.amazon.com/datapipeline/.


The first screen that you see depends on whether you've created a pipeline in the current region.


If you haven't created a pipeline in this region, the console displays an introductory screen. Choose Get started now.


If you've already created a pipeline in this region, the console displays a page that lists your pipelines for the region. Choose Create new pipeline.


In Name, enter a name for your pipeline.


(Optional) In Description, enter a description for your pipeline.


For Source, select Build using Architect.


Under Schedule, choose on pipeline activation.


Under Pipeline Configuration, leave logging enabled. Choose the folder icon under S3 location for logs, select one of your buckets or folders, and then choose Select.


If you prefer, you can disable logging instead.


Under Security/Access, leave IAM roles set to Default.


Click Edit in Architect.


Next, define the Activity object in your pipeline definition. When you define the Activity object, you also define the objects that AWS Data Pipeline must use to perform this activity.
To configure the activity for your pipeline


Click Add activity.


In the Activities pane:


In the Name field, enter a name for the activity, for example, copy-myS3-data.


From Type, select CopyActivity.


From Output, select Create new: DataNode.


From Schedule, select Create new: Schedule.


From Input, select Create new: DataNode.


From Add an optional field, select Runs On.


From the newly added Runs On, select Create new: Resource.


From Add an optional field, select On Success.


From the newly added On Success, select Create new: Action.



In the left pane, separate the icons by dragging them apart. This is a graphical representation of your pipeline. The arrows indicate the connections between the objects.



Next, configure the input and the output data nodes for your pipeline.
To configure the input and output data nodes for your pipeline


In the right pane, click DataNodes.


For DefaultDataNode1, which represents your data source, do the following:


Enter a name for your input node (for example, MyS3Input).


From Type, select S3DataNode.


From Schedule, select your schedule (for example, copy-S3data-schedule).


From Add an optional field, select File Path.


In the File Path field, enter the path in Amazon S3 for your data source.


For DefaultDataNode2, which represents your data target, do the following:


Enter a name for your output node (for example, MyS3Output).


From Type, select S3DataNode. 


From Schedule, select your schedule (for example, copy-S3data-schedule).


From Add an optional field, select File Path.


In the File Path field, enter the path in Amazon S3 for your data target.


Next, configure the resource AWS Data Pipeline must use to perform the copy activity.
To configure the resource


In the right pane, click Resources.


Enter a name for your resource (for example, CopyDataInstance).


From Type, select Ec2Resource.


From Schedule, select your schedule (for example, copy-S3data-schedule).


Leave Resource Role and Role set to their default values.


If you have created your own IAM roles, you can select them if you prefer.
Next, configure the Amazon SNS notification action that AWS Data Pipeline performs after the copy activity finishes successfully.
To configure the notification action


In the right pane, click Others.


Under DefaultAction1, do the following:


Enter a name for your notification (for example, CopyDataNotice).


From Type, select SnsAlarm.


In the Subject field, enter the subject line for your notification.


In the Topic Arn field, enter the ARN of your topic.


In the Message field, enter the message content.


Leave Role field set to the default value.


Save and Validate Your Pipeline
You can save your pipeline definition at any point during the creation process. As soon as you save your pipeline definition, AWS Data Pipeline looks for syntax errors and missing values in your pipeline definition. If your pipeline is incomplete or incorrect, AWS Data Pipeline generates validation errors and warnings. Warning messages are informational only, but you must fix any error messages before you can activate your pipeline.
To save and validate your pipeline


Choose Save pipeline.


AWS Data Pipeline validates your pipeline definition and returns either success or error or warning messages. If you get an error message, choose Close and then, in the right pane, choose Errors/Warnings.


The Errors/Warnings pane lists the objects that failed validation. Choose the plus () sign next to the object names and look for an error message in red.


When you see an error message, go to the specific object pane where you see the error and fix it. For example, if you see an error message in the DataNodes object, go to the DataNodes pane to fix the error.


After you fix the errors listed in the Errors/Warnings pane, choose Save Pipeline.


Repeat the process until your pipeline validates successfully.


Activate Your Pipeline
Activate your pipeline to start creating and processing runs. The pipeline starts based on the schedule and period in your pipeline definition.
Important
If activation succeeds, your pipeline is running and might incur usage charges. For more information, see AWS Data Pipeline pricing. To stop incurring usage charges for AWS Data Pipeline, delete your pipeline.
To activate your pipeline


Choose Activate.


In the confirmation dialog box, choose Close.


Monitor the Pipeline Runs
After you activate your pipeline, you are taken to the Execution details page where you can monitor the progress of your pipeline.
To monitor the progress of your pipeline runs


Choose Update or press F5 to update the status displayed.
Tip
If there are no runs listed, ensure that Start (in UTC) and End (in UTC) cover the scheduled start and end of your pipeline, and then choose Update.


When the status of every object in your pipeline is FINISHED, your pipeline has successfully completed the scheduled tasks. If you created an SNS notification, you should receive email about the successful completion of this task.


If your pipeline doesn't complete successfully, check your pipeline settings for issues. For more information about troubleshooting failed or incomplete instance runs of your pipeline, see Resolving Common Problems.


(Optional) Delete Your Pipeline
To stop incurring charges, delete your pipeline. Deleting your pipeline deletes the pipeline definition and all associated objects.
To delete your pipeline


On the List Pipelines page, select your pipeline.


Click Actions, and then choose Delete.


When prompted for confirmation, choose Delete.

