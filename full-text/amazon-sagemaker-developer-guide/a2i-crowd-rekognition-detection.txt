crowd-rekognition-detect-moderation-labels
A widget to enable human review of an Amazon Rekognition image moderation result.
Attributes
The following attributes are supported by this element.
header
This is the text that is displayed as the header.
src
This is a link to the image to be analyzed by the worker. 
categories
This supports categories as an array of strings or an array of objects where each object has a name field.
If the categories come in as objects, the following applies:
 The displayed categories are the value of the name field.
 The returned answer contains the full objects of any selected categories.
If the categories come in as strings, the following applies:
 The returned answer is an array of all the strings that were selected.
exclusion-category
By setting this attribute you create a button underneath the categories in the UI. 
 When a user chooses the button, all categories are deselected and disabled.
 Choosing the button again re-enables the categories so that users can choose them.
 If you submit after choosing the button, it returns an empty array.
Element Hierarchy
This element has the following parent and child elements.
 Parent elements – crowd-form
 Child elements – full-instructions, short-instructions 
AWS Regions
The following AWS Regions are supported by this element. You can use custom HTML and CSS code within these Regions to format your instructions to workers. For example, use the short-instructions section to provide good and bad examples of how to complete a task. 
full-instructions
General instructions about how to work with the widget. 
short-instructions
Important task-specific instructions that are displayed in a prominent place. 
Example Worker Template with the crowd Element
An example of a worker template using the crowd element would look like the following.
```

{% capture s3_arn %}http://s3.amazonaws.com/{{ task.input.aiServiceRequest.image.s3Object.bucket }}/{{ task.input.aiServiceRequest.image.s3Object.name }}{% endcapture %}

  <crowd-rekognition-detect-moderation-labels
    categories='[
      {% for label in task.input.selectedAiServiceResponse.moderationLabels %}
        {
          name: "{{ label.name }}",
          parentName: "{{ label.parentName }}",
        },
      {% endfor %}
    ]'
    src="{{ s3_arn | grant_read_access }}"
    header="Review the image and choose all applicable categories."

<short-instructions header="Instructions">
  <style>
    .instructions {
      white-space: pre-wrap;
    }
  </style>
  <p class='instructions'>Review the image and choose all applicable categories.

If no categories apply, choose None.

Nudity
Visuals depicting nude male or female person or persons
Graphic Male Nudity
Visuals depicting full frontal male nudity, often close ups
Graphic Female Nudity
Visuals depicting full frontal female nudity, often close ups
Sexual Activity
Visuals depicting various types of explicit sexual activities and pornography
Illustrated Nudity or Sexual Activity
Visuals depicting animated or drawn sexual activity, nudity or pornography
Adult Toys
Visuals depicting adult toys, often in a marketing context
Female Swimwear or Underwear
Visuals depicting female person wearing only swimwear or underwear
Male Swimwear Or Underwear
Visuals depicting male person wearing only swimwear or underwear
Partial Nudity
Visuals depicting covered up nudity, for example using hands or pose
Revealing Clothes
Visuals depicting revealing clothes and poses, such as deep cut dresses
Graphic Violence or Gore
Visuals depicting prominent blood or bloody injuries
Physical Violence
Visuals depicting violent physical assault, such as kicking or punching
Weapon Violence
Visuals depicting violence using weapons like firearms or blades, such as shooting
Weapons
Visuals depicting weapons like firearms and blades
Self Injury
Visuals depicting self-inflicted cutting on the body, typically in distinctive patterns using sharp objects
Emaciated Bodies
Visuals depicting extremely malnourished human bodies
Corpses
Visuals depicting human dead bodies
Hanging
Visuals depicting death by hanging
<full-instructions header="Instructions"></full-instructions>



```
Output
The following is a sample of the output from this element. For details about this output, see Amazon Rekognition DetectModerationLabels API documentation. 
{
  "AWS/Rekognition/DetectModerationLabels/Image/V3": {
    "ModerationLabels": [
        { name: 'Gore', parentName: 'Violence' },
        { name: 'Corpses', parentName: 'Violence' },
    ]
  }
}