ModerationLabel
Provides information about a single type of unsafe content found in an image or video. Each type of moderated content has a label within a hierarchical taxonomy. For more information, see Detecting Unsafe Content.
Contents
Confidence 
Specifies the confidence that Amazon Rekognition has that the label has been correctly identified.
If you don't specify the MinConfidence parameter in the call to DetectModerationLabels, the operation returns labels with a confidence value greater than or equal to 50 percent.
Type: Float
Valid Range: Minimum value of 0. Maximum value of 100.
Required: No
Name 
The label name for the type of unsafe content detected in the image.
Type: String
Required: No
ParentName 
The name for the parent label. Labels at the top level of the hierarchy have the parent label "".
Type: String
Required: No
See Also
For more information about using this API in one of the language-specific AWS SDKs, see the following:
  AWS SDK for C 
  AWS SDK for Go 
  AWS SDK for Java 
  AWS SDK for Ruby V3 