mo.optimize Method
Converts AWS DeepLens model artifacts from a Caffe (.prototxt or .caffemodel), MXNet (.json and .params), or TensorFlow (.pb) representation to an AWS DeepLens representation and performs necessary optimization. 
Syntax
import mo
res = mo.optimize(model_name, input_width, input_height, platform, aux_inputs)
Request Parameters
 model_name: The name of the model to optimize. 
Type: string
Required: Yes
 input_width: The width of the input image in pixels. The value must be a non-negative integer less than or equal to 1024. 
Type: integer.
Required: Yes
 input_height: The height of the input image in pixels. The value must be a non-negative integer less than or equal to 1024. 
Type: integer.
Required: Yes
 platform: The source platform for the optimization. For valid values, see the following table.
Type: string
Required: No
Valid platform Values: 
[See the AWS documentation website for more details]
 aux_inputs: A Python dictionary object that contains auxiliary inputs, including entries common to all platforms and entries specific to individual platforms. 
Type: Dict
Required: No
Valid aux_inputs dictionary Entries 
[See the AWS documentation website for more details]
Returns
The optimize function returns a result that contains the following:
 model_path: Path of the optimized model artifacts when they are successfully returned.
Type: string
 status: Operational status of the function. For possible cause of failures and corrective actions when the method call fails, see the status table below. 
Type: integer  

[See the AWS documentation website for more details]
To load the optimized model for inference, call the awscam.Model API and specify the model_path returned from this function.