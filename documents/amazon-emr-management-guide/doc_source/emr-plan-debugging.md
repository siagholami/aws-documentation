# Configure Cluster Logging and Debugging<a name="emr-plan-debugging"></a>

One of the things to decide as you plan your cluster is how much debugging support you want to make available\. When you are first developing your data processing application, we recommend testing the application on a cluster processing a small, but representative, subset of your data\. When you do this, you will likely want to take advantage of all the debugging tools that Amazon EMR offers, such as archiving log files to Amazon S3\. 

When you've finished development and put your data processing application into full production, you may choose to scale back debugging\. Doing so can save you the cost of storing log file archives in Amazon S3 and reduce processing load on the cluster as it no longer needs to write state to Amazon S3\. The trade off, of course, is that if something goes wrong, you'll have fewer tools available to investigate the issue\. 

## Default Log Files<a name="emr-plan-debugging-logs"></a>

By default, each cluster writes log files on the master node\. These are written to the `/mnt/var/log/` directory\. You can access them by using SSH to connect to the master node as described in [Connect to the Master Node Using SSH](emr-connect-master-node-ssh.md)\. Because these logs exist on the master node, when the node terminates—either because the cluster was shut down or because an error occurred—these log files are no longer available\. 

You do not need to enable anything to have log files written on the master node\. This is the default behavior of Amazon EMR and Hadoop\. 

 A cluster generates several types of log files, including: 
+ **Step logs** — These logs are generated by the Amazon EMR service and contain information about the cluster and the results of each step\. The log files are stored in `/mnt/var/log/hadoop/steps/` directory on the master node\. Each step logs its results in a separate numbered subdirectory: `/mnt/var/log/hadoop/steps/s-stepId1/` for the first step, `/mnt/var/log/hadoop/steps/s-stepId2/`, for the second step, and so on\. The 13\-character step identifiers \(e\.g\. stepId1, stepId2\) are unique to a cluster\.
+ **Hadoop and YARN component logs** — The logs for components associated with both Apache YARN and MapReduce, for example, are contained in separate folders in `/mnt/var/log`\. The log file locations for the Hadoop components under `/mnt/var/log` are as follows: hadoop\-hdfs, hadoop\-mapreduce, hadoop\-httpfs, and hadoop\-yarn\. The hadoop\-state\-pusher directory is for the output of the Hadoop state pusher process\. 
+ **Bootstrap action logs** — If your job uses bootstrap actions, the results of those actions are logged\. The log files are stored in /mnt/var/log/bootstrap\-actions/ on the master node\. Each bootstrap action logs its results in a separate numbered subdirectory: `/mnt/var/log/bootstrap-actions/1/` for the first bootstrap action,` /mnt/var/log/bootstrap-actions/2/`, for the second bootstrap action, and so on\. 
+ **Instance state logs** — These logs provide information about the CPU, memory state, and garbage collector threads of the node\. The log files are stored in `/mnt/var/log/instance-state/` on the master node\. 

## Archive Log Files to Amazon S3<a name="emr-plan-debugging-logs-archive"></a>

**Note**  
You cannot currently use log aggregation to Amazon S3 with the `yarn logs` utility\.

You can configure a cluster to periodically archive the log files stored on the master node to Amazon S3\. This ensures that the log files are available after the cluster terminates, whether this is through normal shut down or due to an error\. Amazon EMR archives the log files to Amazon S3 at 5 minute intervals\. 

To have the log files archived to Amazon S3, you must enable this feature when you launch the cluster\. You can do this using the console, the CLI, or the API\. By default, clusters launched using the console have log archiving enabled\. For clusters launched using the CLI or API, logging to Amazon S3 must be manually enabled\.

**To archive log files to Amazon S3 using the console**

1. Open the Amazon EMR console at [https://console\.aws\.amazon\.com/elasticmapreduce/](https://console.aws.amazon.com/elasticmapreduce/)\.

1. Choose **Create cluster**\.

1. Choose **Go to advanced options**\.

1. In the **Cluster Configuration** section, in the **Logging** field, accept the default option: **Enabled**\. 

   This determines whether Amazon EMR captures detailed log data to Amazon S3\. You can only set this when the cluster is created\. For more information, see [View Log Files](emr-manage-view-web-log-files.md)\.

1. In the **Log folder S3 location** field, type \(or browse to\) an Amazon S3 path to store your logs\. You may also allow the console to generate an Amazon S3 path for you\. If you type the name of a folder that does not exist in the bucket, it is created\.

   When this value is set, Amazon EMR copies the log files from the EC2 instances in the cluster to Amazon S3\. This prevents the log files from being lost when the cluster ends and the EC2 instances hosting the cluster are terminated\. These logs are useful for troubleshooting purposes\. 

   For more information, see [View Log Files](emr-manage-view-web-log-files.md)\.

1. Proceed with creating the cluster as described in [Plan and Configure Clusters](emr-plan.md)\.

**To archive log files to Amazon S3 using the AWS CLI**

To archive log files to Amazon S3 using the AWS CLI, type the `create-cluster` command and specify the Amazon S3 log path using the `--log-uri` parameter\. 
+ To log files to Amazon S3 type the following command and replace *myKey* with the name of your EC2 key pair\.

  ```
  aws emr create-cluster --name "Test cluster" --release-label emr-4.0.0 --log-uri s3://mybucket/logs/ --applications Name=Hadoop Name=Hive Name=Pig --use-default-roles --ec2-attributes KeyName=myKey --instance-type m5.xlarge --instance-count 3
  ```

When you specify the instance count without using the `--instance-groups` parameter, a single Master node is launched, and the remaining instances are launched as core nodes\. All nodes will use the instance type specified in the command\.

**Note**  
If you have not previously created the default EMR service role and EC2 instance profile, type aws `emr create-default-roles` to create them before typing the `create-cluster` subcommand\.

For more information on using Amazon EMR commands in the AWS CLI, see [https://docs.aws.amazon.com/cli/latest/reference/emr](https://docs.aws.amazon.com/cli/latest/reference/emr)\.

**To aggregate logs in Amazon S3 using the AWS CLI**
**Note**  
You cannot currently use log aggregation with the `yarn logs` utility\. You can only use aggregation supported by this procedure\.

Log aggregation \(Hadoop 2\.x\) compiles logs from all containers for an individual application into a single file\. To enable log aggregation to Amazon S3 using the AWS CLI, you use a bootstrap action at cluster launch to enable log aggregation and to specify the bucket to store the logs\.
+ 
**Important**  
This setting has not worked in past 4\.x releases of EMR\. Please use releases greater than 4\.3\.0 if you want to configure this option\. 

  To enable log aggregation create the following configuration file, `myConfig.json`, which contains the following:

  ```
  [
    {
      "Classification": "yarn-site",
      "Properties": {
        "yarn.log-aggregation-enable": "true",
        "yarn.log-aggregation.retain-seconds": "-1",
        "yarn.nodemanager.remote-app-log-dir": "s3:\/\/mybucket\/logs"
      }
    }
  ]
  ```

  Type the following command and replace *myKey* with the name of your EC2 key pair\.

  ```
  aws emr create-cluster --name "Test cluster" --release-label emr-4.5.0 --applications Name=Hadoop --use-default-roles --ec2-attributes KeyName=myKey --instance-type m5.xlarge --instance-count 3 --configurations file://./myConfig.json
  ```

  When you specify the instance count without using the `--instance-groups` parameter, a single Master node is launched, and the remaining instances are launched as core nodes\. All nodes will use the instance type specified in the command\.
**Note**  
If you have not previously created the default EMR service role and EC2 instance profile, type aws `emr create-default-roles` to create them before typing the `create-cluster` subcommand\.

For more information on using Amazon EMR commands in the AWS CLI, see [https://docs.aws.amazon.com/cli/latest/reference/emr](https://docs.aws.amazon.com/cli/latest/reference/emr)\.

## Enable the Debugging Tool<a name="emr-plan-debugging-logs-archive-debug"></a>

 The debugging tool allows you to more easily browse log files from the EMR console\. For more information, see [View Log Files in the Debugging Tool](emr-manage-view-web-log-files.md#emr-manage-view-web-log-files-debug)\. When you enable debugging on a cluster, Amazon EMR archives the log files to Amazon S3 and then indexes those files\. You can then use the console to browse the step, job, task, and task\-attempt logs for the cluster in an intuitive way\.

 To use the debugging tool in the EMR console, you must enable debugging when you launch the cluster using the console, the CLI, or the API\. 

**To enable the debugging tool using the Amazon EMR console**

1. Open the Amazon EMR console at [https://console\.aws\.amazon\.com/elasticmapreduce/](https://console.aws.amazon.com/elasticmapreduce/)\.

1. Choose **Create cluster**\.

1. Choose **Go to advanced options**\.

1. In the **Cluster Configuration** section, in the **Logging** field, choose **Enabled**\. You cannot enable debugging without enabling logging\.

1. In the **Log folder S3 location** field, type an Amazon S3 path to store your logs\.

1. In the **Debugging** field, choose **Enabled**\.

   The debugging option creates an Amazon SQS exchange to publish debugging messages to the Amazon EMR service backend\. Charges for publishing messages to the exchange may apply\. For more information, see [https://aws.amazon.com/sqs](https://aws.amazon.com/sqs)\.

1. Proceed with creating the cluster as described in [Plan and Configure Clusters](emr-plan.md)\.

**To enable the debugging tool using the AWS CLI**

To enable debugging using the AWS CLI, type the `create-cluster` subcommand with the `--enable-debugging` parameter\. You must also specify the `--log-uri` parameter when enabling debugging\. 
+ To enable debugging using the AWS CLI, type the following command and replace *myKey* with the name of your EC2 key pair\.

  ```
  aws emr create-cluster --name "Test cluster" --release-label emr-4.1.0 --log-uri s3://mybucket/logs/ --enable-debugging --applications Name=Hadoop Name=Hive Name=Pig --use-default-roles --ec2-attributes KeyName=myKey --instance-type m5.xlarge --instance-count 3
  ```

  When you specify the instance count without using the `--instance-groups` parameter, a single Master node is launched, and the remaining instances are launched as core nodes\. All nodes will use the instance type specified in the command\.
**Note**  
If you have not previously created the default EMR service role and EC2 instance profile, type aws `emr create-default-roles` to create them before typing the `create-cluster` subcommand\.

For more information on using Amazon EMR commands in the AWS CLI, see [https://docs.aws.amazon.com/cli/latest/reference/emr](https://docs.aws.amazon.com/cli/latest/reference/emr)\.

**Example Enabling debugging using the Java SDK**  
Enable debugging using the following StepConfig:  

```
    StepFactory stepFactory = new StepFactory(); 
	StepConfig enabledebugging = new StepConfig()
   		.withName("Enable debugging")
   		.withActionOnFailure("TERMINATE_JOB_FLOW")
   		.withHadoopJarStep(stepFactory.newEnableDebuggingStep());
```
In this example, `new StepFactory()` uses `us-east-1` as the default region\. If your cluster is launched in a different region, you need to specify the region by using `new StepFactory("region_name.elasticmapreduce")`, such as `new StepFactory("ap-northeast-2.elasticmapreduce")`\.

## Debugging Option Information<a name="emr-plan-debugging-info"></a>

Amazon EMR release 4\.1 or later supports debugging in all regions\.

Amazon EMR creates an Amazon SQS queue to process debugging data\. Message charges may apply\. However, Amazon SQS does have Free Tier of up to 1,000,000 requests available\. For more information, see the [Amazon SQS detail page](https://aws.amazon.com/sqs)\.

Debugging requires the use of roles; your service role and instance profile must allow you to use all Amazon SQS API operations\. If your roles are attached to Amazon EMR managed policies, you do not need to do anything to modify your roles\. If you have custom roles, you need to add `sqs:*` permissions\. For more information, see [Configure IAM Service Roles for Amazon EMR Permissions to AWS Services and Resources](emr-iam-roles.md)\.